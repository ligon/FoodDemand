* Data (Google Sheets)
  #+name: sheets
  - Uganda :: 1mZcHvSD55wGCicdqxbEnioE3AOXM_pVb6zVwHhtBzSk
#
  - Niger :: 1p1-pPd6po4MNq-nkPGzmFplbruJeOMUG_Sq-ygYCVCQ
  - Nigeria :: 1GH9LUNs1rUY21KWwM4_UUNPsmGQek3ohFcjyqm5Bbqw
  - Tanzania :: 1OXY8sRAn0Iu0lLMexcNTg71TWfqhu8ChPLfspKDTMPQ
  - Malawi :: 1Q5sTtRwrDp9HvTvbybcb-yy3ZItWsAPt457mQnIcj1g
  - Ethiopia :: 1_tteDqDLLT8QQY0CICUNS00npBmwUvJcg3PHYPNUsWI


  - ICRISAT :: 13Ig5hZif-NSHtgkKRp_cEgKXk0lOsdUB2BAD6O_FnRo

* Generic code to read data from google sheets & estimate CFE Demands
#+begin_src python :var SHEETS=sheets :tangle /tmp/foo.py
import cfe
import pandas as pd
import numpy as np

Sheets = {k:v for k,v in [s[0].split(" :: ") for s in SHEETS]}

def dataframe_from_gspreadsheet(sheet_name, key):
    """Transform public google spreadsheet into pandas.DataFrame."""
    
    url = 'https://docs.google.com/spreadsheets/d/{key}/gviz/tq?tqx=out:csv&sheet={sheet_name}&headers=1'.format(
        key=key, sheet_name=sheet_name.replace(' ', '%20'))

    print(url)
    df = pd.read_csv(url,dtype={'j':str})

    df.columns = [c.strip() for c in df.columns.tolist()]

    df = df.loc[:,~df.columns.duplicated(keep='first')]   

    df = df.drop([col for col in df.columns if col.startswith('Unnamed')], axis=1)

    df = df.loc[~df.index.duplicated(), :]

    return df


for k,v in Sheets.items():
    print(k)
    x = dataframe_from_gspreadsheet("Expenditures", Sheets[k])

    z = dataframe_from_gspreadsheet("HH Characteristics", Sheets[k])

    # If no 'm' index assume a single market:
    if 'm' not in z.index.names:
        z['m'] = 1
        x['m'] = 1
        z = z.set_index(['j','t','m'])
        x = x.set_index(['j','t','m'])

    x = x.loc[~x.index.duplicated(), :]
    z = z.loc[~z.index.duplicated(), :]

    # Take logs of expenditures; call this y
    y = np.log(x.replace(0, np.nan))
    result = cfe.Result(y=y, z=z, verbose=True)

    result.get_reduced_form()
    result.get_beta()
    result.get_alpha()

    result.to_dataset('./%s.ds' % k)

#+end_src

* Example of Computing Implicit Prices from Consumption & Expenditures
  :PROPERTIES:
  :EXPORT_FILE_NAME: prices.ipynb
  :END:

#+begin_src ipython :tangle /tmp/prices.py
import cfe
import pandas as pd
import numpy as np

Sheets = {"Indian ICRISAT":"13Ig5hZif-NSHtgkKRp_cEgKXk0lOsdUB2BAD6O_FnRo",
          "Uganda":{"Expenditures":"1mZcHvSD55wGCicdqxbEnioE3AOXM_pVb6zVwHhtBzSk",
                    "HH Characteristics":"1mZcHvSD55wGCicdqxbEnioE3AOXM_pVb6zVwHhtBzSk",
                    "Consumption":"1RT5AfbZbWx-CmNaOHLp7aD9qEjgjiBv8lZmPexuKEWg"},
          "Ethiopia":"1tVyKqfI_t7KWmx69Gmj15RyU3_amqf-M0P8hgA9pNi0",
          "Malawi":{"Expenditures":"1-rP6IC2wm91nH94xApeLCXS7dslqlsTns9si57Hs1c0",
                    "HH Characteristics":"1-rP6IC2wm91nH94xApeLCXS7dslqlsTns9si57Hs1c0",
                    "Consumption":"1DgVpSDRG7x7C7WMMwE1nW83brasYkferIdtt81fBanA"},
          "Niger":"1bgtTkbI2WWpPBKaTFO2Nra632UC6hMkB_QFMq8we00o",
          "Nigeria":{"Expenditures":"17L5cDhXRLNAckP3JvBLTLSYIguFqP2ebMvQLH96c0n4",
                     "HH Characteristics":"17L5cDhXRLNAckP3JvBLTLSYIguFqP2ebMvQLH96c0n4",
                     "Consumption":"1kG_fVBmj9EEF9LOwxN30HBxkQENOoWeQjVPYzMJe3b4"},
          "Tanzania":"1QqfWnizPaIyMEspa3NcOS-oDP21EV-4RE-CIIY-7Tuc"}


def dataframe_from_gspreadsheet(sheet_name, key):
    """Transform public google spreadsheet into pandas.DataFrame."""
    
    url = 'https://docs.google.com/spreadsheets/d/{key}/gviz/tq?tqx=out:csv&sheet={sheet_name}&headers=1'.format(
        key=key, sheet_name=sheet_name.replace(' ', '%20'))

    print(url)
    df = pd.read_csv(url,dtype={'j':str})

    df.columns = [c.strip() for c in df.columns.tolist()]

    df = df.loc[:,~df.columns.duplicated(keep='first')]   

    df = df.drop([col for col in df.columns if col.startswith('Unnamed')], axis=1)

    df = df.loc[~df.index.duplicated(), :]

    return df

def prices(Q,X,tol=1e-6):
    """Impute prices from data on expenditures and quantities.

    Non-trivial because quantities may be reported in different units.
    """
    
    myQ = Q.groupby(['j','t','m','u']).sum()

    B={}
    for t in myQ.index.levels[1]:
        for m in myQ.index.levels[2]:
            for i in myQ.columns:
                try:
                    useX = X.query("t==%d and m=='%s'" % (t,m))[i].fillna(0)
                    useQ = myQ.query("t==%d and m=='%s'" % (t,m))[i].fillna(0).unstack('u')
                    if len(useX):
                        q,x = useQ.fillna(0).align(useX.fillna(0),axis=0,join='inner')
                        b = np.linalg.lstsq(q,x,rcond=None)[0]
                        b = pd.Series(b,index=q.columns,name=i)
                        B[(t,m,i)] = b.where(b>0,0).round(6)
                except KeyError:  # i not in X?
                    pass

    P = pd.concat(B).replace(0,np.nan).dropna()
    P.index.names = ['t','m','i','u']

    #P = P.unstack(['i','u'])
    
    return P

for k,v in Sheets.items():
    print(k)
    if type(v) is str:
        v = {"Expenditures":v,"Consumption":v,"HH Characteristics":v}
        
    x = dataframe_from_gspreadsheet("Expenditures", v["Expenditures"])
    c = dataframe_from_gspreadsheet("Consumption", v["Consumption"])

    z = dataframe_from_gspreadsheet("HH Characteristics", v["HH Characteristics"])

    # If no 'm' index assume a single market:
    if 'm' not in z.index.names and 'm' not in z.columns:
        z['m'] = 1
        x['m'] = 1
        c['m'] = 1

    z = z.set_index(['j','t','m'])
    c = c.set_index(['j','t','m'])
    x = x.set_index(['j','t','m'])

    x = x.loc[~x.index.duplicated(), :]
    c = c.loc[~c.index.duplicated(), :]
    z = z.loc[~z.index.duplicated(), :]

    p = prices(c,x)  # Prices for all transactions

    r = cfe.Result(y=np.log(x.replace(0,np.nan)),
                   z=z,
                   prices=p.T, verbose=True)


    r.to_dataset('%s.ds' % k)

    # Fill out the result
    r.get_reduced_form()
    r.get_beta()
    r.get_alpha()
    r.get_predicted_expenditures()

    # Eliminate some expensive arrays

    r.drop_vars(['y','ce','cehat']).to_dataset('/tmp/%s_small.ds' % k)

    r.to_dataset('%s.ds' % k)

#+end_src
