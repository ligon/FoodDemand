#+PROPERTY: header-args:ipython :tangle estimation_example.py

In this document we'll work through a simple approach to estimating
Constant Frisch Elasticity (CFE) demand systems.

There are two prerequisites; the first is the =CFEDemands= python
module, which can be installed with a simple:
#+begin_src ipython :tangle no
!pip install CFEDemands --pre
#+end_src

The second prerequisite is a dataset including detailed information on
household expenditures and characteristics.  The structure of that
dataset is detailed in the next section.

* Data

Consider the case in which the data are saved in a google sheet; we'll
turn data from these into =pandas= dataframes.  
There are limits on the allowable size of google sheets (5 million
cells), so if your dataset is larger than this you'll need some other
mechanism to get your data into such dataframes.  Even in this latter
case you'll want your dataframes to have a structure that matches the
description given below.

** Structure of the Spreadsheet

An example spreadsheet can be found at
https://docs.google.com/spreadsheets/d/13Ig5hZif-NSHtgkKRp_cEgKXk0lOsdUB2BAD6O_FnRo/.

This spreadsheet consists of two worksheets, labeled "Expenditures"
and "Household Characteristics", respectively.

Each worksheet has the initial three columns labeled "j", "t", and
"m"; together these identify an observation uniquely.  The column "j"
should include a household id; the column "t" should include an
indicator for the year or period (for those of you with
cross-sectional data these will all take a common value, e.g., 2019);
the column "m" should be an indicator of "market", which may be a
region identifier, or may take a single value (e.g., "Malawi").

The triple (j,t,m) will serve as the index of some constructed
dataframes.  It is important not to have *too* many different values
for "m" (unless you have lots of RAM to play with).

Beyond the first three columns, the "Expenditures" worksheet should
have one column for each category of expenditures (e.g., "Rice", "Goat
meat", "Millet",...).

Beyond the first three columns, the "Household Characteristics" should
have columns corresponding to different elements of the vector of
observable characteristics $z$.  If the data allow, I recommend
constructing observables that match what I have in the ICRISAT data:
namely numbers of "Men", "Women", "Boys" and "Girls"; also the
logarithm of total household size ("log HSize").

** From Sheet to DataFrame to Result Object

We begin by defining a dictionary that contains the spreadsheet key. 
One is provided for the Indian ICRISAT example that I wish to work
through. 
#+begin_src ipython :results silent  :tangle estimation_example.py
ICRISAT_Data = '13Ig5hZif-NSHtgkKRp_cEgKXk0lOsdUB2BAD6O_FnRo' 
#+end_src

With the spreadsheet defined , grab it and define a couple of
dataframes. Note that the spreadsheet must be public for this approach
to work; if you want to keep this private consider using private
keys.  

#+begin_src ipython :results silent  :tangle estimation_example.py
import pandas as pd
import numpy as np
from eep153_tools import read_sheets

#### Need private keys from json file (we're authenticating using "service accounts")
#!gpg --batch --passphrase "SECRET PASSPHRASE" -d ../students-9093fa174318.json.gpg > ../students-9093fa174318.json
####

# Add credentials if sheet not meant to be public
x = read_sheets(ICRISAT_Data,sheet='Expenditures',json_creds='../students-9093fa174318.json')
                 
# Change 'ICRISAT' to key of your own sheet in Sheets, above
z = read_sheets(ICRISAT_Data,sheet="HH Characteristics",json_creds='../students-9093fa174318.json')

# Assume a single market: (Comment this out to make each village its own market)
z['m'] = 1
x['m'] = 1

x = x.replace(0,np.nan) # Replace zeros with missing

# Take logs of expenditures; call this y
y = np.log(x.set_index(['j','t','m']))

z.set_index(['j','t','m'],inplace=True)
#+end_src

This gives a dataframe of household characteristics $z$ with a simple structure.

#+begin_src ipython :tangle no
z.head()
#+end_src

Also a dataframe of log expenditures $y$ with a similarly simple
structure.  Note that any expenditures of zero are dropped and
replaced with a missing value indicator.
#+begin_src ipython :tangle no
y.head()
#+end_src

With nothing more than this, we can estimate the demand system.  This
happens in two steps.  The first is the "reduced form" step:

#+begin_src ipython  :results silent :tangle estimation_example.py
import cfe

result = cfe.Result(y=y,z=z)
#+end_src

This creates a complicated "Result" object, with lots of different
attributes.  Note from below that attributes $y$ and $z$ are now defined.

#+begin_src ipython :tangle no
result
#+end_src

** First step of Estimation

Recall that there are two steps to estimation; the first step
involves estimating the "reduced form" linear regression 
\[
y_{it}^j = {a}_{it} + \delta_i'{z}^j_t + \epsilon_{it}^j.
\]

The Result class has code to estimate this in one line:
#+begin_src ipython  :results silent
result.get_reduced_form()
#+end_src

After running this we can examine the estimated coefficients $\delta$:
#+begin_src ipython
result.delta.to_dataframe().unstack('k')
#+end_src

Also the good-time constants $a_{it}$ (this captures the effects of prices)
#+begin_src ipython
result.a.to_dataframe().unstack('i')
#+end_src

** Second step of Estimation

The second step involves using Singular Value Decomposition to find
the rank one matrix that best approximates the residuals $e_{it}^j$.
This can be interpreted as
\[
    -\beta_i\log\lambda^j_t,
\]
where the $\log\lambda^j_t$ is the log of the marginal utility of
expenditures (MUE) for household $j$ at time $t$, and where $\beta_i$ are
the corresponding "Frisch elasticities" that tell us how much
demand changes as the MUE falls.

Estimates can also be computed as a one-liner:
#+begin_src ipython  
result.get_beta(as_df=True)
#+end_src

That's all there is to estimation!  Note that we didn't estimate
demands for all goods---lots of goods didn't have enough observations,
and were automatically dropped.  (This can be controlled using the
=min_proportion_items= and =min_xproducts= attributes when one
instantiates the result object.)

** Assessment of Fit
Now, let's see how we did, by comparing total expenditures predicted by the
model we've estimated with actual total expenditures:

#+begin_src ipython :tangle no
import matplotlib.pyplot as plt
%matplotlib inline
import matplotlib.cm as cm

xbar = np.exp(result.y).sum(['m','i']).to_dataframe('xbar').replace(0,np.nan).squeeze()
xhat = result.get_predicted_expenditures().sum(['m','i']).to_dataframe('xhat').replace(0,np.nan).squeeze()

# Make dataframe of actual & predicted
df = pd.DataFrame({'Actual':np.log(xbar),'Predicted':np.log(xhat)})

df.plot.scatter(x='Predicted',y='Actual')

# Add 45 degree line
v = plt.axis()
vmin = np.max([v[0],v[2]])
vmax = np.max([v[1],v[3]])
plt.plot([vmin,vmax],[vmin,vmax])
#+end_src



** Predicting Positive Consumption
An issue with our assessment of fit is that we /predicted/ that every
household would consume positive quantitites of every good, and in
making our assessment we ignored the (many) cases in which in fact the
household had zero expenditures on that good.  

Here we're going to go back and use similar framework to try and
estimate the probability with which we'll observe zero expenditures
as a function of \lambda, prices, and household characteristics.

#+begin_src ipython :tangle no
import matplotlib.pyplot as plt
%matplotlib inline
import matplotlib.cm as cm

zeros_r = cfe.Result(y=(0.+(result.y>0)),z=result.z)
weights = zeros_r.get_predicted_log_expenditures()

# Truncate to make weights live in [0,1]
weights = weights.where((weights<1) + np.isnan(weights),1).where((weights>0) + np.isnan(weights),0)

xbar = np.exp(result.y).sum(['m','i']).to_dataframe('xbar').replace(0,np.nan).squeeze()

# Calculate *expected* predicted expenditures, to make unconditional on being positive
xhat = (weights*result.get_predicted_expenditures()).sum(['m','i']).to_dataframe('xhat').replace(0,np.nan).squeeze()

# Make dataframe of actual & predicted
df = pd.DataFrame({'Actual':np.log(xbar),'Predicted':np.log(xhat)})

df.plot.scatter(x='Predicted',y='Actual')

# Add 45 degree line
v = plt.axis()
vmin = np.max([v[0],v[2]])
vmax = np.max([v[1],v[3]])
plt.plot([vmin,vmax],[vmin,vmax])
#+end_src



